name: Ingest StatsCan Data

on:
  workflow_dispatch:
    inputs:
      limit:
        description: 'Max datasets (leave empty for no limit)'
        required: false

jobs:
  ingest:
    runs-on: ubuntu-latest
    timeout-minutes: 360

    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_REGION: us-east-2
      PYTHONUNBUFFERED: 1

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: pip install pandas boto3 requests pyarrow

      - name: Download base catalog
        run: |
          aws s3 cp s3://build-cananda-dw/statscan/catalog/catalog.parquet catalog.parquet

      - name: Run ingestion
        env:
          LIMIT: ${{ github.event.inputs.limit }}
        run: python -m src.pipeline.ingest_all

      - name: Upload to S3
        run: python -m src.pipeline.upload_to_s3

      - name: Regenerate catalog
        run: python -m src.pipeline.regenerate_catalog

      - name: Update Glue crawler
        run: python -m src.pipeline.update_crawler

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ingestion-manifest
          path: |
            ingested.csv
            dataset_folders.txt
